{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdd90c4-fda4-4b99-9b32-2d255c8ec6cd",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594d64b-4c48-4c88-b607-2b0a8542b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdae5c3-2b6a-43ff-ad5f-566cd27bb1bf",
   "metadata": {},
   "source": [
    "### pre_processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01768972-ae4e-4072-8c4e-1995915b0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\PC\\Documents\\train-metadata.csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "#debugging information to check the imbalance in the data\n",
    "before = data['target'].value_counts()\n",
    "\n",
    "majority = data[data['target'] == 0]\n",
    "minority = data[data['target'] == 1]\n",
    "#fix the imbalance by upsamling the minority class to match the majority\n",
    "minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42) \n",
    "data = pd.concat([majority, minority_upsampled]) #combine them to the final result\n",
    "\n",
    "#check the 2 classes after fixing the imbalance\n",
    "after = data['target'].value_counts()\n",
    "\n",
    "print(f\"Data distribution before balancing: {before}\")\n",
    "print(f\"Data distribution after balancing: {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3952d5-95ec-44e0-9fb6-5de4b3d15ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns that are irrelevant or repetitive \n",
    "data.drop(columns=['isic_id', 'patient_id', 'image_type', 'tbp_tile_type', 'copyright_license', \n",
    "                   'lesion_id', 'iddx_full', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5', \n",
    "                   'mel_mitotic_index', 'mel_thick_mm'], inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49a4cf-07b0-4192-9fb3-26708f65938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [col for col in data.select_dtypes(include=['float64', 'int64']).columns if col != 'target'] #identify numeric columns\n",
    "categorical = data.select_dtypes(include=['object']).columns #identify categorical columns\n",
    "imputer_num = SimpleImputer(strategy='mean')  #create instance of imputer with mean to fill the missing data\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')  #create instance of imputer with mode to fill the missing data\n",
    "\n",
    "data[numeric] = imputer_num.fit_transform(data[numeric])\n",
    "data[categorical] = imputer_cat.fit_transform(data[categorical])\n",
    "print(data.isnull().sum()) #verify handling all missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea830da-0ca6-45c2-8a01-f3106e464842",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________\n",
    "All missing values have been handled, and the dataset is now fully preprocessed and ready for analysis or modeling\n",
    "____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e645fb3-982e-43bc-8aa6-ac4849487922",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### visuallization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ba575-feb6-412f-883a-b40a7f1ae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count plot shows comparison between age distribution against having cancer\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.countplot(x='sex', hue='target', data=data, palette='Set3')\n",
    "plt.title('Count Plot of Age against Having Cancer')\n",
    "plt.xlabel('sex')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212a747-608f-4268-ae8d-8c39c2a8547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot compares anatomical site against age, and its effect on having cancer\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x='anatom_site_general',\n",
    "    y='age_approx',\n",
    "    hue='target',\n",
    "    palette='coolwarm')\n",
    "plt.title('Age vs Anatomical Site')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Anatomical Site')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb972837-ac53-47ad-8699-f1e52941284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram distribution of the anatomical site locations, highlighting the frequency of each site in the dataset.\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.hist(data['tbp_lv_location'], bins=20)\n",
    "plt.title('Histogram Distribution of Anatomical Site')\n",
    "plt.xlabel('anatom site general')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae997a25-c262-48f4-a3b6-509a5c2553a5",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________\n",
    "We used various plot types (count plot, box plot, and histogram) to visualize different aspects of the data, \n",
    "which helped us identify patterns in age distribution, gender differences, \n",
    "and the distribution of anatomical sites across the dataset.\n",
    "____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91661c9f-1a65-40aa-98c7-f697cbb67617",
   "metadata": {},
   "source": [
    "## cleaning data (normalizaion and dropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b70b13-9c7b-48f6-bfaf-a3d4c40ada2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling all numeric values to be within [0,1] range for faster convergence\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric] = scaler.fit_transform(data[numeric])\n",
    "data[numeric].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51c8a4-5736-4a42-b3c2-3e4a9375d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all categorical data to numeric\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical:\n",
    "    data[col] = encoder.fit_transform(data[col])\n",
    "\n",
    "data[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043f41c-052e-4c7f-a678-91c0d2dac8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate the X and y data\n",
    "\n",
    "X = data.iloc[ : , 1: ]\n",
    "y = data.iloc[ : , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add48f6-2b89-46a0-879b-3833bb9e82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for model using pytorch type\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9182ca-d565-4a8f-aa83-8e6d65ebb98a",
   "metadata": {},
   "source": [
    "#  Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c7dd2-eff5-464f-912d-ecefe066e71e",
   "metadata": {},
   "source": [
    "### NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6200b8c-0923-4d0c-91bc-0afd8ac116bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into %85 training and %25 testing datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6026f96-8cda-47ab-a083-0b60e7d839bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataset into Dataloader for the model to train on it\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=400, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a82780-562d-4534-bcae-61cf984f82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple fully connected neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        #only 3 layers (one hidden) and a drop rate, all to prevent overfitting\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x) #output layer, outputs raw logits\n",
    "        return x\n",
    "\n",
    "n = X.shape[1] #number of features (columns)\n",
    "model = SimpleNN(n)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() #uses sigmoid activation function, and binary cross entropy loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1163d-c9af-4e81-89ce-06785eeda204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin training the model\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #initialze the training loss measurement\n",
    "    training_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.train() #set the model in train mode\n",
    "    \n",
    "    for X_batch, y_batch in train_loader: #using the batches from loader\n",
    "        \n",
    "        optimizer.zero_grad()#clear gradient from previous step\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward() #compute gradient by backpropagation\n",
    "        optimizer.step() #update the parameters accordingly\n",
    "        training_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    training_loss /= len(train_loader)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} -> Training Loss: {training_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d502b8e-9f88-46a1-b376-14cf95c01aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin testing the model\n",
    "\n",
    "model.eval() #set the model to evaluation mode\n",
    "with torch.no_grad(): #disable gradient computing during testing\n",
    "    #create list for the prediction and actual result and intialize the loss to 0\n",
    "    test_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for X_batch, y_batch in test_loader: #using the batches from loader\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item() #keep on adding the loss from the iteration\n",
    "\n",
    "        #compute the predicted y and its corresponding actual y\n",
    "        predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        y_true.extend(y_batch.numpy())\n",
    "        y_pred.extend(predictions.numpy())\n",
    "\n",
    "    #compute evaluation criteria \n",
    "    test_loss /= len(test_loader)#calculate the average of the loss function\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Average test loss: {test_loss:.8f}')\n",
    "print(f'Accuracy: %{accuracy * 100}')\n",
    "print(f'F1 score: %{f1 * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a458b-f367-446a-9802-545a5fec8a93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c6ea8-b26d-4086-99e4-189da9476b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#initialize r=classifier random forest \n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=70,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#predict and evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: %{accuracy * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34e120-5cb3-4ec0-9b4b-9a58569a9507",
   "metadata": {},
   "source": [
    "### CNN model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b343c-45f0-43da-823b-2bae653f0f01",
   "metadata": {},
   "source": [
    "#### pre_processing images and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1d61f-d2b5-4727-b35c-a7c31e939701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af455388-8167-44bc-ba80-bfefdb303ba9",
   "metadata": {},
   "source": [
    "#### Subset of the images processed to be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040ef26-e030-4b78-a303-0687171a8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "#resize the image for model training later\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "#apply CLAHE to enhance contrast in images\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "#remove hair using morphology operations\n",
    "def remove_hair(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _, thresh = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    dst = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "\n",
    "#adjust brightness using gamma correction\n",
    "def adjust_gamma(image, gamma=1.3):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "#sharpen the image\n",
    "def sharpen_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (0, 0), sigmaX=55, sigmaY=55)\n",
    "    sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
    "    return sharpened\n",
    "\n",
    "#function to apply all the preprocessing technique used an image\n",
    "def preprocess_image(image_path):\n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    resized_image = resize_image(image)\n",
    "    clahe_image = apply_clahe(resized_image)\n",
    "    hair_removed_image = remove_hair(clahe_image)\n",
    "    gamma_corrected_image = adjust_gamma(hair_removed_image)\n",
    "    sharpened_image = sharpen_image(gamma_corrected_image)\n",
    "    return sharpened_image\n",
    "\n",
    "#function to preprocess all the images\n",
    "def process_image_folder(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            processed_image = preprocess_image(file_path)\n",
    "            if processed_image is not None:\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                cv2.imwrite(output_path, processed_image, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                print(f\"Processed and saved: {filename}\")\n",
    "\n",
    "    print(f\"All images in {input_dir} have been processed and saved to {output_dir}\")\n",
    "\n",
    "input_folder =  r\"C:\\Users\\PC\\Documents\\isic-2024-challenge\\train-image\\image\" #path to the training images\n",
    "output_folder = r\"C:\\Users\\PC\\Documents\\isic-2024-challenge\\train-image\\trained_im_preprocessed\"\n",
    "\n",
    "process_image_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e392e71-13ed-4ee1-9683-46e304c01864",
   "metadata": {},
   "source": [
    "#### Creating a dataset consisting of image titles and their corresponding labels only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f395c0-78d7-47d9-b0bd-42623786613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csvr(\"C:\\Users\\PC\\Documents\\train-metadata.csv\\train-metadata.csv\")\n",
    "df.info(verbose = False, memory_usage = 'deep')\n",
    "\n",
    "req_cols= ['isic_id', 'target']\n",
    "df= pd.read_csv(\"C:\\Users\\PC\\Documents\\isic-2024-challenge\\train-metadata.csv\", usecols= req_cols)\n",
    "y= df['target']\n",
    "x = df.drop(['target'], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab26c34-441f-4d5e-975f-f3681b6e5ca5",
   "metadata": {},
   "source": [
    "#### CNN model that deals with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5847677-47d2-408e-acb7-f3a6b2b18619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path =  r'C:\\Users\\PC\\Documents\\isic-2024-challenge\\labels_sub.csv'  # Adjust path to your CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Path to the folder containing the images\n",
    "images_folder =  r\"C:\\Users\\PC\\Documents\\isic-2024-challenge\\train-image\\trained_im_preprocessed\"  # Adjust path to your image folder\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224  # Resize all images to 224x224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images_and_labels(df, image_folder, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Get image filename and label\n",
    "        img_filename = row['isic_id'] + '.jpg'  # Assuming your image IDs are in the column 'isic_id'\n",
    "        img_path = os.path.join(image_folder, img_filename)\n",
    "        \n",
    "        # Load image\n",
    "        img = load_img(img_path, target_size=(img_size, img_size))\n",
    "        img = img_to_array(img) / 255.0  # Normalize image to range [0, 1]\n",
    "        \n",
    "        # Append image and label\n",
    "        images.append(img)\n",
    "        labels.append(row['target'])  # Assuming labels are in 'target' column (0 or 1)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load images and labels\n",
    "X, y = load_images_and_labels(df, images_folder)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical (if necessary, for multi-class classification)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 output classes: benign (0) and malignant (1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the model if needed\n",
    "model.save('cnn_skin_lesion_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8466cc3-e624-4a4c-9a17-314fa10cf48a",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f14f2cb-bc17-4d4a-8e14-31d31181c556",
   "metadata": {},
   "source": [
    "The NN model performed with Accuracy: %99.99875208246239\n",
    "The random forest classifier performed with Accuracy: %99.99937604123119\n",
    "The CNN model performed with Accuracy: %99.88"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
